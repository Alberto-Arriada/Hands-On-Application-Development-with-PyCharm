{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook explores the keystroke dataset for the study titled __High-accuracy\n",
    "detection of early Parkinson's Disease using multiple characteristics of finger\n",
    "movement while typing__. The notebook goes through various data-cleaning\n",
    "techniques to clean and consolidate the provided data files. A number of\n",
    "observations and visualizations are also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reading in data\n",
    "\n",
    "The provided data files are divided into two sub-folders:\n",
    "- Folder 1: `Archived users`, which contains information on the participants'\n",
    "details (gender, year of diagnosis, whether the participant has tremors, etc.)\n",
    "- Folder 2: `Tappy Data`, which contains keystroke statistics from specific\n",
    "participants (hold time, current hand, previous hand, etc.)\n",
    "\n",
    "Here we are getting a list of all the files present in the `Archived users`\n",
    "folder. However, not all users in the above set have a corresponding typing\n",
    "data in the `Tappy Data` folder. We therefore compute the intersection of these\n",
    "two sets, i.e. the user IDs that both have a user data file in Folder 1, and a\n",
    "typing data file in Folder 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Tappy Data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-41e98f576057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtappy_file_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/Tappy Data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0muser_set_v2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtappy_file_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [: 10] to return just the user IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Tappy Data/'"
     ]
    }
   ],
   "source": [
    "user_file_list = os.listdir('../data/Archived users/')\n",
    "user_set_v1 = set(map(lambda x: x[5: 15], user_file_list))  # [5: 15] to return just the user IDs\n",
    "\n",
    "\n",
    "tappy_file_list = os.listdir('data/Tappy Data/')\n",
    "user_set_v2 = set(map(lambda x: x[: 10], tappy_file_list))  # [: 10] to return just the user IDs\n",
    "\n",
    "\n",
    "user_set = user_set_v1.intersection(user_set_v2)\n",
    "\n",
    "len(user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_user_file(file_name):\n",
    "    f = open('../input/Archived-users/Archived users/' + file_name)\n",
    "    data = [line.split(': ')[1][: -1] for line in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "files = os.listdir('../input/Archived-users/Archived users/')\n",
    "\n",
    "columns = [\n",
    "    'BirthYear', 'Gender', 'Parkinsons', 'Tremors', 'DiagnosisYear',\n",
    "    'Sided', 'UPDRS', 'Impact', 'Levadopa', 'DA', 'MAOB', 'Other'\n",
    "]\n",
    "\n",
    "user_df = pd.DataFrame(columns=columns) # empty Data Frame for now\n",
    "\n",
    "for user_id in user_set:\n",
    "    temp_file_name = 'User_' + user_id + '.txt' # tappy file names have the format of `User_[UserID].txt`\n",
    "    if temp_file_name in files: # check to see if the user ID is in our valid user set\n",
    "        temp_data = read_user_file(temp_file_name)\n",
    "        user_df.loc[user_id] = temp_data # adding data to our DataFrame\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and preprocessing\n",
    "\n",
    "Data in a number of columns needs to be processed, cleaned, or reformatted.\n",
    "First, we are changing data in `BirthYear` and `DiagnosisYear` to a numeric\n",
    "format, if a cell has an invalid data format, change it to `NaN`. (For example,\n",
    "row 2, `DianosisYear` column above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# force some columns to have numeric data type\n",
    "user_df['BirthYear'] = pd.to_numeric(user_df['BirthYear'], errors='coerce')\n",
    "user_df['DiagnosisYear'] = pd.to_numeric(user_df['DiagnosisYear'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding binary data: some columns have True-False data values, here we are\n",
    "converting it to binary data (0s and 1s), for better data processing by machine\n",
    "learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_df = user_df.rename(index=str, columns={'Gender': 'Female'})  # renaming `Gender` to `Female`\n",
    "user_df['Female'] = user_df['Female'] == 'Female'  # change string data to boolean data\n",
    "user_df['Female'] = user_df['Female'].astype(int)  # change boolean data to binary data\n",
    "\n",
    "str_to_binary_columns = ['Parkinsons', 'Tremors', 'Levadopa', 'DA', 'MAOB', 'Other']  # columns to be converted to binary data\n",
    "\n",
    "for column in str_to_binary_columns:\n",
    "    user_df[column] = user_df[column] == 'True'\n",
    "    user_df[column] = user_df[column].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variables: some categorical data will now be converted to mutually\n",
    "exclusive binary data through dummy variables (aka one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prior processing for `Impact` column\n",
    "user_df.loc[\n",
    "    (user_df['Impact'] != 'Medium') &\n",
    "    (user_df['Impact'] != 'Mild') &\n",
    "    (user_df['Impact'] != 'Severe'), 'Impact'] = 'None'\n",
    "\n",
    "\n",
    "to_dummy_column_indices = ['Sided', 'UPDRS', 'Impact']  # columns to be one-hot encoded\n",
    "\n",
    "for column in to_dummy_column_indices:\n",
    "    user_df = pd.concat([\n",
    "        user_df.iloc[:, : user_df.columns.get_loc(column)],\n",
    "        pd.get_dummies(user_df[column], prefix=str(column)),\n",
    "        user_df.iloc[:, user_df.columns.get_loc(column) + 1 :]\n",
    "    ], axis=1)\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "Missing data count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "missing_data = user_df.isnull().sum()\n",
    "\n",
    "g = sns.barplot(missing_data.index, missing_data)\n",
    "g.set_xticklabels(labels=missing_data.index, rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birth year distribution, gender count, and tremor count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "\n",
    "sns.distplot(\n",
    "    user_df.loc[user_df['Parkinsons'] == 0, 'BirthYear'].dropna(axis=0),\n",
    "    kde_kws = {'label': \"Without Parkinson's\"},\n",
    "    ax = ax[0][0]\n",
    ")\n",
    "sns.distplot(\n",
    "    user_df.loc[user_df['Parkinsons'] == 1, 'BirthYear'].dropna(axis=0),\n",
    "    kde_kws = {'label': \"With Parkinson's\"},\n",
    "    ax = ax[0][1]\n",
    ")\n",
    "\n",
    "sns.countplot(x='Female', hue='Parkinsons', data=user_df, ax=ax[1][0])\n",
    "sns.countplot(x='Tremors', hue='Parkinsons', data=user_df, ax=ax[1][1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating the second dataset\n",
    "\n",
    "Here we will read in a file in our second folder and explore it. From that we\n",
    "will consequently write a general function to process similar files later on.\n",
    "\n",
    "(Note that the data in the `Hold time`, `Latency time`, and `Flight time`\n",
    "columns are in milliseconds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name = '0EA27ICBLF_1607.txt'  # an arbitrary file to explore\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'data/Tappy Data/' + file_name,\n",
    "    delimiter = '\\t',\n",
    "    index_col = False,\n",
    "    names = ['UserKey', 'Date', 'Timestamp', 'Hand', 'Hold time', 'Direction', 'Latency time', 'Flight time']\n",
    ")\n",
    "\n",
    "df = df.drop('UserKey', axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will be using the `pd.to_datetime()` and `pd.to_numeric()` functions to\n",
    "force-convert our data to be stored in the correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format='%y%M%d').dt.date\n",
    "# converting time data to numeric\n",
    "for column in ['Hold time', 'Latency time', 'Flight time']:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, below we are dropping any entries that don't have the correct data\n",
    "in the `Hand` and `Direction` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cleaning data in Hand\n",
    "df = df[\n",
    "    (df['Hand'] == 'L') |\n",
    "    (df['Hand'] == 'R') |\n",
    "    (df['Hand'] == 'S')\n",
    "]\n",
    "\n",
    "# cleaning data in Direction\n",
    "df = df[\n",
    "    (df['Direction'] == 'LL') |\n",
    "    (df['Direction'] == 'LR') |\n",
    "    (df['Direction'] == 'LS') |\n",
    "    (df['Direction'] == 'RL') |\n",
    "    (df['Direction'] == 'RR') |\n",
    "    (df['Direction'] == 'RS') |\n",
    "    (df['Direction'] == 'SL') |\n",
    "    (df['Direction'] == 'SR') |\n",
    "    (df['Direction'] == 'SS')\n",
    "]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, we will only be looking at the mean (average) time of the\n",
    "`Hold time`, `Latency time`, and `Flight time` columns in groups of the same\n",
    "`Direction` data. In other words, we will split our current Pandas dataframe\n",
    "into groups of `LL` direction, of `LS` direction, of `LR` direction, and so on.\n",
    "(`L` denotes left hand, `R` denotes right hand, and `S` denotes the spacebar).\n",
    "\n",
    "This calculation could be achived easily by the function `groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "direction_group_df = df.groupby('Direction').mean()\n",
    "direction_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that this is simply a summary of keystroke data of a specific user at a\n",
    "specific time period. For the sake of convenience, we will put all the commands\n",
    "above into a function to process this data. Note that the function will return\n",
    "the data in an ordered NumPy array for the sake of runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_tappy(file_name):\n",
    "    df = pd.read_csv(\n",
    "        'data/Tappy Data/' + file_name,\n",
    "        delimiter = '\\t',\n",
    "        index_col = False,\n",
    "        names = ['UserKey', 'Date', 'Timestamp', 'Hand', 'Hold time',\n",
    "                 'Direction', 'Latency time', 'Flight time']\n",
    "    )\n",
    "\n",
    "    df = df.drop('UserKey', axis=1)\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format='%y%M%d').dt.date\n",
    "\n",
    "    # Convert time data to numeric\n",
    "    for column in ['Hold time', 'Latency time', 'Flight time']:\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    df = df.dropna(axis=0)\n",
    "\n",
    "    # Clean data in `Hand`\n",
    "    df = df[\n",
    "        (df['Hand'] == 'L') |\n",
    "        (df['Hand'] == 'R') |\n",
    "        (df['Hand'] == 'S')\n",
    "    ]\n",
    "\n",
    "    # Clean data in `Direction`\n",
    "    df = df[\n",
    "        (df['Direction'] == 'LL') |\n",
    "        (df['Direction'] == 'LR') |\n",
    "        (df['Direction'] == 'LS') |\n",
    "        (df['Direction'] == 'RL') |\n",
    "        (df['Direction'] == 'RR') |\n",
    "        (df['Direction'] == 'RS') |\n",
    "        (df['Direction'] == 'SL') |\n",
    "        (df['Direction'] == 'SR') |\n",
    "        (df['Direction'] == 'SS')\n",
    "    ]\n",
    "\n",
    "    direction_group_df = df.groupby('Direction').mean()\n",
    "    del df; gc.collect()\n",
    "    \n",
    "    direction_group_df = direction_group_df.reindex(\n",
    "        ['LL', 'LR', 'LS', 'RL', 'RR', 'RS', 'SL', 'SR', 'SS'])\n",
    "    direction_group_df = direction_group_df.sort_index()  # to ensure correct order of data\n",
    "    \n",
    "    return direction_group_df.values.flatten()  # returning a numppy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a user can have multiple typing data files ranging multiple months (for\n",
    "example, `0EA27ICBLF` has `0EA27ICBLF_1607.txt` and `0EA27ICBLF_1608.txt`), we\n",
    "are now writing a function that takes in a user ID, searches for all typing\n",
    "data files for that user, and returns the mean of corresponding `Direction` and\n",
    "`Time` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_user(user_id, filenames):\n",
    "    running_user_data = np.array([])\n",
    "\n",
    "    for filename in filenames:\n",
    "        if user_id in filename:\n",
    "            running_user_data = np.append(running_user_data, read_tappy(filename))\n",
    "    \n",
    "    running_user_data = np.reshape(running_user_data, (-1, 27))  # flatten time data\n",
    "    \n",
    "    return np.nanmean(running_user_data, axis=0)  # ignoring NaNs while calculating the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will loop through all user IDs we have in our `user_df` DataFrame,\n",
    "calling our `process_user()` function and creating a new DataFrame in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filenames = os.listdir('data/Tappy Data/')\n",
    "\n",
    "column_names = [first_hand + second_hand + '_' + time \n",
    "                for first_hand in ['L', 'R', 'S'] \n",
    "                for second_hand in ['L', 'R', 'S'] \n",
    "                for time in ['Hold time', 'Latency time', 'Flight time']]\n",
    "\n",
    "user_tappy_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for user_id in user_df.index:\n",
    "    user_tappy_data = process_user(str(user_id), filenames)\n",
    "    user_tappy_df.loc[user_id] = user_tappy_data\n",
    "\n",
    "# Some preliminary data cleaning\n",
    "user_tappy_df = user_tappy_df.fillna(0)\n",
    "user_tappy_df[user_tappy_df < 0] = 0    \n",
    "\n",
    "user_tappy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are concatenating the `user_df` DataFrame, which contains information\n",
    "on the users (year of birth, year of diagnosis, drug use, etc.), and the\n",
    "`user_tappy_df` DataFrame, which contains typing data for corresponding users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combined_user_df = pd.concat([user_df, user_tappy_df], axis=1)\n",
    "combined_user_df.to_csv('data/combined_user.csv')\n",
    "\n",
    "combined_user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "We will use boxplots to visualize distributions of different time data (hold\n",
    "time, latency time, and flight time) between participants with and without\n",
    "Parkinsons's. Each subplot will contain data in a specific typing switch\n",
    "type--for example, the top left subplot contains typing data when participants\n",
    "go from a left-hand key to another left-hand key (denoted as `LL` above the\n",
    "subplot), while the top right one contains data when participants switch from a\n",
    "left-hand key to a space (`LS`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(10, 5))\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    right = 3,\n",
    "    top = 3\n",
    ")\n",
    "\n",
    "for i in range(9):\n",
    "    temp_columns = column_names[3 * i : 3 * i + 3]\n",
    "    stacked_df = combined_user_df[temp_columns].stack().reset_index()\n",
    "    \n",
    "    stacked_df = stacked_df.rename(\n",
    "        columns={'level_0': 'index', 'level_1': 'Type', 0: 'Time'})\n",
    "    stacked_df = stacked_df.set_index('index')\n",
    "\n",
    "    for index in stacked_df.index:\n",
    "        stacked_df.loc[index, 'Parkinsons'] = combined_user_df.loc[index, 'Parkinsons']\n",
    "    \n",
    "    sns.boxplot(x='Type', y='Time',\n",
    "                hue='Parkinsons',\n",
    "                data=stacked_df,\n",
    "                ax=ax[i // 3][i % 3]\n",
    "                ).set_title(column_names[i * 3][: 2], fontsize=20)\n",
    "    \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
